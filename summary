O SHAP Summary Plot é uma representação visual que explica como um modelo de machine learning toma suas decisões, mostrando a importância de cada variável e seu impacto nas previsões. Ele funciona calculando, para cada observação no conjunto de dados, a contribuição específica de cada feature em relação à previsão média do modelo. No gráfico, as variáveis são organizadas verticalmente em ordem de importância, da mais relevante no topo até a menos influente na base. Horizontalmente, os valores SHAP indicam o quanto cada feature altera a saída do modelo em relação à sua média. Cada ponto no gráfico corresponde a uma observação, com cores que variam do azul (valores baixos da feature) ao vermelho (valores altos), permitindo identificar padrões de influência.

A interpretação do SHAP Summary revela três aspectos principais: primeiro, a importância relativa das features, onde uma maior dispersão horizontal indica maior influência no modelo; segundo, a direção do impacto, observando se valores altos (vermelhos) tendem a puxar a previsão para a direita (aumentando o resultado) ou para a esquerda (diminuindo-o), e vice-versa para valores baixos (azuis); e terceiro, a consistência do efeito, analisando se uma feature age sempre na mesma direção ou se seu impacto varia conforme o caso. Por exemplo, em um modelo de aprovação de crédito, se a variável "renda" aparece no topo com pontos vermelhos concentrados à direita, isso sugere que maiores rendas aumentam a probabilidade de aprovação, enquanto rendas baixas (azuis) à esquerda indicam o oposto. Já uma feature como "número de dívidas" poderia mostrar pontos azuis à direita, sinalizando que menos dívidas favorecem a aprovação.

Essa visualização é especialmente útil para entender não apenas quais variáveis o modelo considera importantes, mas também como elas operam — se de forma linear, não linear ou até com efeitos condicionais dependendo de outros fatores. Além disso, ela ajuda a identificar possíveis vieses ou relações contraditórias que merecem investigação.
